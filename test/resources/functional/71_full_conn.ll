; ModuleID = 'module'
source_filename = "module"

declare i32 @getint()
declare i32 @getch()
declare i32 @getarray(i32*)
declare void @putint(i32)
declare void @putch(i32)
declare void @putarray(i32, i32*)

define i32 @relu_reg(i32 %a) {
relu_regEntry:
  %a_arg = alloca i32, align 4
  store i32 %a, i32* %a_arg, align 4
  %__tmp0 = load i32, i32* %a_arg, align 4
  %__tmp1 = icmp sgt i32 %__tmp0, 127
  br i1 %__tmp1, label %bb0, label %bb1
bb0:
  ret i32 127
bb1:
  br label %bb2
bb2:
  %__tmp2 = load i32, i32* %a_arg, align 4
  %__tmp3 = icmp slt i32 %__tmp2, 0
  br i1 %__tmp3, label %bb3, label %bb4
bb3:
  ret i32 0
bb4:
  br label %bb5
bb5:
  %__tmp4 = load i32, i32* %a_arg, align 4
  ret i32 %__tmp4
}

define i32 @model([5 x i32]* %a) {
modelEntry:
  %a_arg = alloca [5 x i32]*, align 4
  store [5 x i32]* %a, [5 x i32]** %a_arg, align 4
  %__tmp0 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp0, i64 0
  %__tmp2 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1, i64 0, i64 0
  %__tmp3 = load i32, i32* %__tmp2, align 4
  %__tmp4 = mul i32 %__tmp3, 85
  %__tmp5 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp6 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp5, i64 0
  %__tmp7 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp6, i64 0, i64 1
  %__tmp8 = load i32, i32* %__tmp7, align 4
  %__tmp9 = mul i32 %__tmp8, 23
  %__tmp10 = add i32 %__tmp4, %__tmp9
  %__tmp11 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp12 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp11, i64 0
  %__tmp13 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp12, i64 0, i64 2
  %__tmp14 = load i32, i32* %__tmp13, align 4
  %__tmp15 = mul i32 %__tmp14, -82
  %__tmp16 = add i32 %__tmp10, %__tmp15
  %__tmp17 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp18 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp17, i64 0
  %__tmp19 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp18, i64 0, i64 3
  %__tmp20 = load i32, i32* %__tmp19, align 4
  %__tmp21 = mul i32 %__tmp20, -103
  %__tmp22 = add i32 %__tmp16, %__tmp21
  %__tmp23 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp24 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp23, i64 0
  %__tmp25 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp24, i64 0, i64 4
  %__tmp26 = load i32, i32* %__tmp25, align 4
  %__tmp27 = mul i32 %__tmp26, -123
  %__tmp28 = add i32 %__tmp22, %__tmp27
  %__tmp29 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp30 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp29, i64 1
  %__tmp31 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp30, i64 0, i64 0
  %__tmp32 = load i32, i32* %__tmp31, align 4
  %__tmp33 = mul i32 %__tmp32, 64
  %__tmp34 = add i32 %__tmp28, %__tmp33
  %__tmp35 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp36 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp35, i64 1
  %__tmp37 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp36, i64 0, i64 1
  %__tmp38 = load i32, i32* %__tmp37, align 4
  %__tmp39 = mul i32 %__tmp38, -120
  %__tmp40 = add i32 %__tmp34, %__tmp39
  %__tmp41 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp42 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp41, i64 1
  %__tmp43 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp42, i64 0, i64 2
  %__tmp44 = load i32, i32* %__tmp43, align 4
  %__tmp45 = mul i32 %__tmp44, 50
  %__tmp46 = add i32 %__tmp40, %__tmp45
  %__tmp47 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp48 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp47, i64 1
  %__tmp49 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp48, i64 0, i64 3
  %__tmp50 = load i32, i32* %__tmp49, align 4
  %__tmp51 = mul i32 %__tmp50, -59
  %__tmp52 = add i32 %__tmp46, %__tmp51
  %__tmp53 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp54 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp53, i64 1
  %__tmp55 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp54, i64 0, i64 4
  %__tmp56 = load i32, i32* %__tmp55, align 4
  %__tmp57 = mul i32 %__tmp56, 47
  %__tmp58 = add i32 %__tmp52, %__tmp57
  %__tmp59 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp60 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp59, i64 2
  %__tmp61 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp60, i64 0, i64 0
  %__tmp62 = load i32, i32* %__tmp61, align 4
  %__tmp63 = mul i32 %__tmp62, -111
  %__tmp64 = add i32 %__tmp58, %__tmp63
  %__tmp65 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp66 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp65, i64 2
  %__tmp67 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp66, i64 0, i64 1
  %__tmp68 = load i32, i32* %__tmp67, align 4
  %__tmp69 = mul i32 %__tmp68, -67
  %__tmp70 = add i32 %__tmp64, %__tmp69
  %__tmp71 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp72 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp71, i64 2
  %__tmp73 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp72, i64 0, i64 2
  %__tmp74 = load i32, i32* %__tmp73, align 4
  %__tmp75 = mul i32 %__tmp74, -106
  %__tmp76 = add i32 %__tmp70, %__tmp75
  %__tmp77 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp78 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp77, i64 2
  %__tmp79 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp78, i64 0, i64 3
  %__tmp80 = load i32, i32* %__tmp79, align 4
  %__tmp81 = mul i32 %__tmp80, -75
  %__tmp82 = add i32 %__tmp76, %__tmp81
  %__tmp83 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp84 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp83, i64 2
  %__tmp85 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp84, i64 0, i64 4
  %__tmp86 = load i32, i32* %__tmp85, align 4
  %__tmp87 = mul i32 %__tmp86, -102
  %__tmp88 = add i32 %__tmp82, %__tmp87
  %__tmp89 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp90 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp89, i64 3
  %__tmp91 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp90, i64 0, i64 0
  %__tmp92 = load i32, i32* %__tmp91, align 4
  %__tmp93 = mul i32 %__tmp92, 34
  %__tmp94 = add i32 %__tmp88, %__tmp93
  %__tmp95 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp96 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp95, i64 3
  %__tmp97 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp96, i64 0, i64 1
  %__tmp98 = load i32, i32* %__tmp97, align 4
  %__tmp99 = mul i32 %__tmp98, -39
  %__tmp100 = add i32 %__tmp94, %__tmp99
  %__tmp101 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp102 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp101, i64 3
  %__tmp103 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp102, i64 0, i64 2
  %__tmp104 = load i32, i32* %__tmp103, align 4
  %__tmp105 = mul i32 %__tmp104, 65
  %__tmp106 = add i32 %__tmp100, %__tmp105
  %__tmp107 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp108 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp107, i64 3
  %__tmp109 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp108, i64 0, i64 3
  %__tmp110 = load i32, i32* %__tmp109, align 4
  %__tmp111 = mul i32 %__tmp110, 47
  %__tmp112 = add i32 %__tmp106, %__tmp111
  %__tmp113 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp114 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp113, i64 3
  %__tmp115 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp114, i64 0, i64 4
  %__tmp116 = load i32, i32* %__tmp115, align 4
  %__tmp117 = mul i32 %__tmp116, 113
  %__tmp118 = add i32 %__tmp112, %__tmp117
  %__tmp119 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp120 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp119, i64 4
  %__tmp121 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp120, i64 0, i64 0
  %__tmp122 = load i32, i32* %__tmp121, align 4
  %__tmp123 = mul i32 %__tmp122, 110
  %__tmp124 = add i32 %__tmp118, %__tmp123
  %__tmp125 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp126 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp125, i64 4
  %__tmp127 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp126, i64 0, i64 1
  %__tmp128 = load i32, i32* %__tmp127, align 4
  %__tmp129 = mul i32 %__tmp128, 47
  %__tmp130 = add i32 %__tmp124, %__tmp129
  %__tmp131 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp132 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp131, i64 4
  %__tmp133 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp132, i64 0, i64 2
  %__tmp134 = load i32, i32* %__tmp133, align 4
  %__tmp135 = mul i32 %__tmp134, -4
  %__tmp136 = add i32 %__tmp130, %__tmp135
  %__tmp137 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp138 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp137, i64 4
  %__tmp139 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp138, i64 0, i64 3
  %__tmp140 = load i32, i32* %__tmp139, align 4
  %__tmp141 = mul i32 %__tmp140, 80
  %__tmp142 = add i32 %__tmp136, %__tmp141
  %__tmp143 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp144 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp143, i64 4
  %__tmp145 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp144, i64 0, i64 4
  %__tmp146 = load i32, i32* %__tmp145, align 4
  %__tmp147 = mul i32 %__tmp146, 46
  %__tmp148 = add i32 %__tmp142, %__tmp147
  %__tmp149 = call i32 @relu_reg(i32 %__tmp148)
  %__tmp150 = mul i32 %__tmp149, 39
  %__tmp151 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp152 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp151, i64 0
  %__tmp153 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp152, i64 0, i64 0
  %__tmp154 = load i32, i32* %__tmp153, align 4
  %__tmp155 = mul i32 %__tmp154, -106
  %__tmp156 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp157 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp156, i64 0
  %__tmp158 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp157, i64 0, i64 1
  %__tmp159 = load i32, i32* %__tmp158, align 4
  %__tmp160 = mul i32 %__tmp159, 126
  %__tmp161 = add i32 %__tmp155, %__tmp160
  %__tmp162 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp163 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp162, i64 0
  %__tmp164 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp163, i64 0, i64 2
  %__tmp165 = load i32, i32* %__tmp164, align 4
  %__tmp166 = mul i32 %__tmp165, -18
  %__tmp167 = add i32 %__tmp161, %__tmp166
  %__tmp168 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp169 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp168, i64 0
  %__tmp170 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp169, i64 0, i64 3
  %__tmp171 = load i32, i32* %__tmp170, align 4
  %__tmp172 = mul i32 %__tmp171, -31
  %__tmp173 = add i32 %__tmp167, %__tmp172
  %__tmp174 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp175 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp174, i64 0
  %__tmp176 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp175, i64 0, i64 4
  %__tmp177 = load i32, i32* %__tmp176, align 4
  %__tmp178 = mul i32 %__tmp177, -8
  %__tmp179 = add i32 %__tmp173, %__tmp178
  %__tmp180 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp181 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp180, i64 1
  %__tmp182 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp181, i64 0, i64 0
  %__tmp183 = load i32, i32* %__tmp182, align 4
  %__tmp184 = mul i32 %__tmp183, 47
  %__tmp185 = add i32 %__tmp179, %__tmp184
  %__tmp186 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp187 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp186, i64 1
  %__tmp188 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp187, i64 0, i64 1
  %__tmp189 = load i32, i32* %__tmp188, align 4
  %__tmp190 = mul i32 %__tmp189, -4
  %__tmp191 = add i32 %__tmp185, %__tmp190
  %__tmp192 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp193 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp192, i64 1
  %__tmp194 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp193, i64 0, i64 2
  %__tmp195 = load i32, i32* %__tmp194, align 4
  %__tmp196 = mul i32 %__tmp195, 67
  %__tmp197 = add i32 %__tmp191, %__tmp196
  %__tmp198 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp199 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp198, i64 1
  %__tmp200 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp199, i64 0, i64 3
  %__tmp201 = load i32, i32* %__tmp200, align 4
  %__tmp202 = mul i32 %__tmp201, -94
  %__tmp203 = add i32 %__tmp197, %__tmp202
  %__tmp204 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp205 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp204, i64 1
  %__tmp206 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp205, i64 0, i64 4
  %__tmp207 = load i32, i32* %__tmp206, align 4
  %__tmp208 = mul i32 %__tmp207, -121
  %__tmp209 = add i32 %__tmp203, %__tmp208
  %__tmp210 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp211 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp210, i64 2
  %__tmp212 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp211, i64 0, i64 0
  %__tmp213 = load i32, i32* %__tmp212, align 4
  %__tmp214 = mul i32 %__tmp213, 7
  %__tmp215 = add i32 %__tmp209, %__tmp214
  %__tmp216 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp217 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp216, i64 2
  %__tmp218 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp217, i64 0, i64 1
  %__tmp219 = load i32, i32* %__tmp218, align 4
  %__tmp220 = mul i32 %__tmp219, -21
  %__tmp221 = add i32 %__tmp215, %__tmp220
  %__tmp222 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp223 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp222, i64 2
  %__tmp224 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp223, i64 0, i64 2
  %__tmp225 = load i32, i32* %__tmp224, align 4
  %__tmp226 = mul i32 %__tmp225, -60
  %__tmp227 = add i32 %__tmp221, %__tmp226
  %__tmp228 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp229 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp228, i64 2
  %__tmp230 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp229, i64 0, i64 3
  %__tmp231 = load i32, i32* %__tmp230, align 4
  %__tmp232 = mul i32 %__tmp231, -43
  %__tmp233 = add i32 %__tmp227, %__tmp232
  %__tmp234 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp235 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp234, i64 2
  %__tmp236 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp235, i64 0, i64 4
  %__tmp237 = load i32, i32* %__tmp236, align 4
  %__tmp238 = mul i32 %__tmp237, 105
  %__tmp239 = add i32 %__tmp233, %__tmp238
  %__tmp240 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp241 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp240, i64 3
  %__tmp242 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp241, i64 0, i64 0
  %__tmp243 = load i32, i32* %__tmp242, align 4
  %__tmp244 = mul i32 %__tmp243, -42
  %__tmp245 = add i32 %__tmp239, %__tmp244
  %__tmp246 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp247 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp246, i64 3
  %__tmp248 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp247, i64 0, i64 1
  %__tmp249 = load i32, i32* %__tmp248, align 4
  %__tmp250 = mul i32 %__tmp249, 87
  %__tmp251 = add i32 %__tmp245, %__tmp250
  %__tmp252 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp253 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp252, i64 3
  %__tmp254 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp253, i64 0, i64 2
  %__tmp255 = load i32, i32* %__tmp254, align 4
  %__tmp256 = mul i32 %__tmp255, 29
  %__tmp257 = add i32 %__tmp251, %__tmp256
  %__tmp258 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp259 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp258, i64 3
  %__tmp260 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp259, i64 0, i64 3
  %__tmp261 = load i32, i32* %__tmp260, align 4
  %__tmp262 = mul i32 %__tmp261, -106
  %__tmp263 = add i32 %__tmp257, %__tmp262
  %__tmp264 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp265 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp264, i64 3
  %__tmp266 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp265, i64 0, i64 4
  %__tmp267 = load i32, i32* %__tmp266, align 4
  %__tmp268 = mul i32 %__tmp267, -31
  %__tmp269 = add i32 %__tmp263, %__tmp268
  %__tmp270 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp271 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp270, i64 4
  %__tmp272 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp271, i64 0, i64 0
  %__tmp273 = load i32, i32* %__tmp272, align 4
  %__tmp274 = mul i32 %__tmp273, -110
  %__tmp275 = add i32 %__tmp269, %__tmp274
  %__tmp276 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp277 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp276, i64 4
  %__tmp278 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp277, i64 0, i64 1
  %__tmp279 = load i32, i32* %__tmp278, align 4
  %__tmp280 = mul i32 %__tmp279, -100
  %__tmp281 = add i32 %__tmp275, %__tmp280
  %__tmp282 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp283 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp282, i64 4
  %__tmp284 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp283, i64 0, i64 2
  %__tmp285 = load i32, i32* %__tmp284, align 4
  %__tmp286 = mul i32 %__tmp285, -22
  %__tmp287 = add i32 %__tmp281, %__tmp286
  %__tmp288 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp289 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp288, i64 4
  %__tmp290 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp289, i64 0, i64 3
  %__tmp291 = load i32, i32* %__tmp290, align 4
  %__tmp292 = mul i32 %__tmp291, -75
  %__tmp293 = add i32 %__tmp287, %__tmp292
  %__tmp294 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp295 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp294, i64 4
  %__tmp296 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp295, i64 0, i64 4
  %__tmp297 = load i32, i32* %__tmp296, align 4
  %__tmp298 = mul i32 %__tmp297, -125
  %__tmp299 = add i32 %__tmp293, %__tmp298
  %__tmp300 = call i32 @relu_reg(i32 %__tmp299)
  %__tmp301 = mul i32 %__tmp300, 77
  %__tmp302 = add i32 %__tmp150, %__tmp301
  %__tmp303 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp304 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp303, i64 0
  %__tmp305 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp304, i64 0, i64 0
  %__tmp306 = load i32, i32* %__tmp305, align 4
  %__tmp307 = mul i32 %__tmp306, 26
  %__tmp308 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp309 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp308, i64 0
  %__tmp310 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp309, i64 0, i64 1
  %__tmp311 = load i32, i32* %__tmp310, align 4
  %__tmp312 = mul i32 %__tmp311, 76
  %__tmp313 = add i32 %__tmp307, %__tmp312
  %__tmp314 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp315 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp314, i64 0
  %__tmp316 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp315, i64 0, i64 2
  %__tmp317 = load i32, i32* %__tmp316, align 4
  %__tmp318 = mul i32 %__tmp317, -70
  %__tmp319 = add i32 %__tmp313, %__tmp318
  %__tmp320 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp321 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp320, i64 0
  %__tmp322 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp321, i64 0, i64 3
  %__tmp323 = load i32, i32* %__tmp322, align 4
  %__tmp324 = mul i32 %__tmp323, 29
  %__tmp325 = add i32 %__tmp319, %__tmp324
  %__tmp326 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp327 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp326, i64 0
  %__tmp328 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp327, i64 0, i64 4
  %__tmp329 = load i32, i32* %__tmp328, align 4
  %__tmp330 = mul i32 %__tmp329, -95
  %__tmp331 = add i32 %__tmp325, %__tmp330
  %__tmp332 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp333 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp332, i64 1
  %__tmp334 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp333, i64 0, i64 0
  %__tmp335 = load i32, i32* %__tmp334, align 4
  %__tmp336 = mul i32 %__tmp335, 96
  %__tmp337 = add i32 %__tmp331, %__tmp336
  %__tmp338 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp339 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp338, i64 1
  %__tmp340 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp339, i64 0, i64 1
  %__tmp341 = load i32, i32* %__tmp340, align 4
  %__tmp342 = mul i32 %__tmp341, 52
  %__tmp343 = add i32 %__tmp337, %__tmp342
  %__tmp344 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp345 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp344, i64 1
  %__tmp346 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp345, i64 0, i64 2
  %__tmp347 = load i32, i32* %__tmp346, align 4
  %__tmp348 = mul i32 %__tmp347, -68
  %__tmp349 = add i32 %__tmp343, %__tmp348
  %__tmp350 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp351 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp350, i64 1
  %__tmp352 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp351, i64 0, i64 3
  %__tmp353 = load i32, i32* %__tmp352, align 4
  %__tmp354 = mul i32 %__tmp353, -5
  %__tmp355 = add i32 %__tmp349, %__tmp354
  %__tmp356 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp357 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp356, i64 1
  %__tmp358 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp357, i64 0, i64 4
  %__tmp359 = load i32, i32* %__tmp358, align 4
  %__tmp360 = mul i32 %__tmp359, 34
  %__tmp361 = add i32 %__tmp355, %__tmp360
  %__tmp362 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp363 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp362, i64 2
  %__tmp364 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp363, i64 0, i64 0
  %__tmp365 = load i32, i32* %__tmp364, align 4
  %__tmp366 = mul i32 %__tmp365, -34
  %__tmp367 = add i32 %__tmp361, %__tmp366
  %__tmp368 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp369 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp368, i64 2
  %__tmp370 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp369, i64 0, i64 1
  %__tmp371 = load i32, i32* %__tmp370, align 4
  %__tmp372 = mul i32 %__tmp371, 102
  %__tmp373 = add i32 %__tmp367, %__tmp372
  %__tmp374 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp375 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp374, i64 2
  %__tmp376 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp375, i64 0, i64 2
  %__tmp377 = load i32, i32* %__tmp376, align 4
  %__tmp378 = mul i32 %__tmp377, 6
  %__tmp379 = add i32 %__tmp373, %__tmp378
  %__tmp380 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp381 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp380, i64 2
  %__tmp382 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp381, i64 0, i64 3
  %__tmp383 = load i32, i32* %__tmp382, align 4
  %__tmp384 = mul i32 %__tmp383, -38
  %__tmp385 = add i32 %__tmp379, %__tmp384
  %__tmp386 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp387 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp386, i64 2
  %__tmp388 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp387, i64 0, i64 4
  %__tmp389 = load i32, i32* %__tmp388, align 4
  %__tmp390 = mul i32 %__tmp389, 27
  %__tmp391 = add i32 %__tmp385, %__tmp390
  %__tmp392 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp393 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp392, i64 3
  %__tmp394 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp393, i64 0, i64 0
  %__tmp395 = load i32, i32* %__tmp394, align 4
  %__tmp396 = mul i32 %__tmp395, 110
  %__tmp397 = add i32 %__tmp391, %__tmp396
  %__tmp398 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp399 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp398, i64 3
  %__tmp400 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp399, i64 0, i64 1
  %__tmp401 = load i32, i32* %__tmp400, align 4
  %__tmp402 = mul i32 %__tmp401, 116
  %__tmp403 = add i32 %__tmp397, %__tmp402
  %__tmp404 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp405 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp404, i64 3
  %__tmp406 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp405, i64 0, i64 2
  %__tmp407 = load i32, i32* %__tmp406, align 4
  %__tmp408 = mul i32 %__tmp407, 39
  %__tmp409 = add i32 %__tmp403, %__tmp408
  %__tmp410 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp411 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp410, i64 3
  %__tmp412 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp411, i64 0, i64 3
  %__tmp413 = load i32, i32* %__tmp412, align 4
  %__tmp414 = mul i32 %__tmp413, -63
  %__tmp415 = add i32 %__tmp409, %__tmp414
  %__tmp416 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp417 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp416, i64 3
  %__tmp418 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp417, i64 0, i64 4
  %__tmp419 = load i32, i32* %__tmp418, align 4
  %__tmp420 = mul i32 %__tmp419, -99
  %__tmp421 = add i32 %__tmp415, %__tmp420
  %__tmp422 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp423 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp422, i64 4
  %__tmp424 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp423, i64 0, i64 0
  %__tmp425 = load i32, i32* %__tmp424, align 4
  %__tmp426 = mul i32 %__tmp425, 65
  %__tmp427 = add i32 %__tmp421, %__tmp426
  %__tmp428 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp429 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp428, i64 4
  %__tmp430 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp429, i64 0, i64 1
  %__tmp431 = load i32, i32* %__tmp430, align 4
  %__tmp432 = mul i32 %__tmp431, 120
  %__tmp433 = add i32 %__tmp427, %__tmp432
  %__tmp434 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp435 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp434, i64 4
  %__tmp436 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp435, i64 0, i64 2
  %__tmp437 = load i32, i32* %__tmp436, align 4
  %__tmp438 = mul i32 %__tmp437, -39
  %__tmp439 = add i32 %__tmp433, %__tmp438
  %__tmp440 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp441 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp440, i64 4
  %__tmp442 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp441, i64 0, i64 3
  %__tmp443 = load i32, i32* %__tmp442, align 4
  %__tmp444 = mul i32 %__tmp443, -6
  %__tmp445 = add i32 %__tmp439, %__tmp444
  %__tmp446 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp447 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp446, i64 4
  %__tmp448 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp447, i64 0, i64 4
  %__tmp449 = load i32, i32* %__tmp448, align 4
  %__tmp450 = mul i32 %__tmp449, 94
  %__tmp451 = add i32 %__tmp445, %__tmp450
  %__tmp452 = call i32 @relu_reg(i32 %__tmp451)
  %__tmp453 = mul i32 %__tmp452, 127
  %__tmp454 = add i32 %__tmp302, %__tmp453
  %__tmp455 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp456 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp455, i64 0
  %__tmp457 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp456, i64 0, i64 0
  %__tmp458 = load i32, i32* %__tmp457, align 4
  %__tmp459 = mul i32 %__tmp458, -23
  %__tmp460 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp461 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp460, i64 0
  %__tmp462 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp461, i64 0, i64 1
  %__tmp463 = load i32, i32* %__tmp462, align 4
  %__tmp464 = mul i32 %__tmp463, -63
  %__tmp465 = add i32 %__tmp459, %__tmp464
  %__tmp466 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp467 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp466, i64 0
  %__tmp468 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp467, i64 0, i64 2
  %__tmp469 = load i32, i32* %__tmp468, align 4
  %__tmp470 = mul i32 %__tmp469, 49
  %__tmp471 = add i32 %__tmp465, %__tmp470
  %__tmp472 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp473 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp472, i64 0
  %__tmp474 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp473, i64 0, i64 3
  %__tmp475 = load i32, i32* %__tmp474, align 4
  %__tmp476 = mul i32 %__tmp475, 50
  %__tmp477 = add i32 %__tmp471, %__tmp476
  %__tmp478 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp479 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp478, i64 0
  %__tmp480 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp479, i64 0, i64 4
  %__tmp481 = load i32, i32* %__tmp480, align 4
  %__tmp482 = mul i32 %__tmp481, 72
  %__tmp483 = add i32 %__tmp477, %__tmp482
  %__tmp484 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp485 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp484, i64 1
  %__tmp486 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp485, i64 0, i64 0
  %__tmp487 = load i32, i32* %__tmp486, align 4
  %__tmp488 = mul i32 %__tmp487, 85
  %__tmp489 = add i32 %__tmp483, %__tmp488
  %__tmp490 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp491 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp490, i64 1
  %__tmp492 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp491, i64 0, i64 1
  %__tmp493 = load i32, i32* %__tmp492, align 4
  %__tmp494 = mul i32 %__tmp493, -30
  %__tmp495 = add i32 %__tmp489, %__tmp494
  %__tmp496 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp497 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp496, i64 1
  %__tmp498 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp497, i64 0, i64 2
  %__tmp499 = load i32, i32* %__tmp498, align 4
  %__tmp500 = mul i32 %__tmp499, 12
  %__tmp501 = add i32 %__tmp495, %__tmp500
  %__tmp502 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp503 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp502, i64 1
  %__tmp504 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp503, i64 0, i64 3
  %__tmp505 = load i32, i32* %__tmp504, align 4
  %__tmp506 = mul i32 %__tmp505, 125
  %__tmp507 = add i32 %__tmp501, %__tmp506
  %__tmp508 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp509 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp508, i64 1
  %__tmp510 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp509, i64 0, i64 4
  %__tmp511 = load i32, i32* %__tmp510, align 4
  %__tmp512 = mul i32 %__tmp511, -117
  %__tmp513 = add i32 %__tmp507, %__tmp512
  %__tmp514 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp515 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp514, i64 2
  %__tmp516 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp515, i64 0, i64 0
  %__tmp517 = load i32, i32* %__tmp516, align 4
  %__tmp518 = mul i32 %__tmp517, -65
  %__tmp519 = add i32 %__tmp513, %__tmp518
  %__tmp520 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp521 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp520, i64 2
  %__tmp522 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp521, i64 0, i64 1
  %__tmp523 = load i32, i32* %__tmp522, align 4
  %__tmp524 = mul i32 %__tmp523, -67
  %__tmp525 = add i32 %__tmp519, %__tmp524
  %__tmp526 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp527 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp526, i64 2
  %__tmp528 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp527, i64 0, i64 2
  %__tmp529 = load i32, i32* %__tmp528, align 4
  %__tmp530 = mul i32 %__tmp529, 125
  %__tmp531 = add i32 %__tmp525, %__tmp530
  %__tmp532 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp533 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp532, i64 2
  %__tmp534 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp533, i64 0, i64 3
  %__tmp535 = load i32, i32* %__tmp534, align 4
  %__tmp536 = mul i32 %__tmp535, 110
  %__tmp537 = add i32 %__tmp531, %__tmp536
  %__tmp538 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp539 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp538, i64 2
  %__tmp540 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp539, i64 0, i64 4
  %__tmp541 = load i32, i32* %__tmp540, align 4
  %__tmp542 = mul i32 %__tmp541, -31
  %__tmp543 = add i32 %__tmp537, %__tmp542
  %__tmp544 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp545 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp544, i64 3
  %__tmp546 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp545, i64 0, i64 0
  %__tmp547 = load i32, i32* %__tmp546, align 4
  %__tmp548 = mul i32 %__tmp547, -123
  %__tmp549 = add i32 %__tmp543, %__tmp548
  %__tmp550 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp551 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp550, i64 3
  %__tmp552 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp551, i64 0, i64 1
  %__tmp553 = load i32, i32* %__tmp552, align 4
  %__tmp554 = mul i32 %__tmp553, 83
  %__tmp555 = add i32 %__tmp549, %__tmp554
  %__tmp556 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp557 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp556, i64 3
  %__tmp558 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp557, i64 0, i64 2
  %__tmp559 = load i32, i32* %__tmp558, align 4
  %__tmp560 = mul i32 %__tmp559, 122
  %__tmp561 = add i32 %__tmp555, %__tmp560
  %__tmp562 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp563 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp562, i64 3
  %__tmp564 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp563, i64 0, i64 3
  %__tmp565 = load i32, i32* %__tmp564, align 4
  %__tmp566 = mul i32 %__tmp565, 11
  %__tmp567 = add i32 %__tmp561, %__tmp566
  %__tmp568 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp569 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp568, i64 3
  %__tmp570 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp569, i64 0, i64 4
  %__tmp571 = load i32, i32* %__tmp570, align 4
  %__tmp572 = mul i32 %__tmp571, -23
  %__tmp573 = add i32 %__tmp567, %__tmp572
  %__tmp574 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp575 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp574, i64 4
  %__tmp576 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp575, i64 0, i64 0
  %__tmp577 = load i32, i32* %__tmp576, align 4
  %__tmp578 = mul i32 %__tmp577, -47
  %__tmp579 = add i32 %__tmp573, %__tmp578
  %__tmp580 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp581 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp580, i64 4
  %__tmp582 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp581, i64 0, i64 1
  %__tmp583 = load i32, i32* %__tmp582, align 4
  %__tmp584 = mul i32 %__tmp583, -32
  %__tmp585 = add i32 %__tmp579, %__tmp584
  %__tmp586 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp587 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp586, i64 4
  %__tmp588 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp587, i64 0, i64 2
  %__tmp589 = load i32, i32* %__tmp588, align 4
  %__tmp590 = mul i32 %__tmp589, -117
  %__tmp591 = add i32 %__tmp585, %__tmp590
  %__tmp592 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp593 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp592, i64 4
  %__tmp594 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp593, i64 0, i64 3
  %__tmp595 = load i32, i32* %__tmp594, align 4
  %__tmp596 = mul i32 %__tmp595, 95
  %__tmp597 = add i32 %__tmp591, %__tmp596
  %__tmp598 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp599 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp598, i64 4
  %__tmp600 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp599, i64 0, i64 4
  %__tmp601 = load i32, i32* %__tmp600, align 4
  %__tmp602 = mul i32 %__tmp601, 118
  %__tmp603 = add i32 %__tmp597, %__tmp602
  %__tmp604 = call i32 @relu_reg(i32 %__tmp603)
  %__tmp605 = mul i32 %__tmp604, -106
  %__tmp606 = add i32 %__tmp454, %__tmp605
  %__tmp607 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp608 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp607, i64 0
  %__tmp609 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp608, i64 0, i64 0
  %__tmp610 = load i32, i32* %__tmp609, align 4
  %__tmp611 = mul i32 %__tmp610, 8
  %__tmp612 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp613 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp612, i64 0
  %__tmp614 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp613, i64 0, i64 1
  %__tmp615 = load i32, i32* %__tmp614, align 4
  %__tmp616 = mul i32 %__tmp615, 82
  %__tmp617 = add i32 %__tmp611, %__tmp616
  %__tmp618 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp619 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp618, i64 0
  %__tmp620 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp619, i64 0, i64 2
  %__tmp621 = load i32, i32* %__tmp620, align 4
  %__tmp622 = mul i32 %__tmp621, -104
  %__tmp623 = add i32 %__tmp617, %__tmp622
  %__tmp624 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp625 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp624, i64 0
  %__tmp626 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp625, i64 0, i64 3
  %__tmp627 = load i32, i32* %__tmp626, align 4
  %__tmp628 = mul i32 %__tmp627, 101
  %__tmp629 = add i32 %__tmp623, %__tmp628
  %__tmp630 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp631 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp630, i64 0
  %__tmp632 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp631, i64 0, i64 4
  %__tmp633 = load i32, i32* %__tmp632, align 4
  %__tmp634 = mul i32 %__tmp633, -116
  %__tmp635 = add i32 %__tmp629, %__tmp634
  %__tmp636 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp637 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp636, i64 1
  %__tmp638 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp637, i64 0, i64 0
  %__tmp639 = load i32, i32* %__tmp638, align 4
  %__tmp640 = mul i32 %__tmp639, -63
  %__tmp641 = add i32 %__tmp635, %__tmp640
  %__tmp642 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp643 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp642, i64 1
  %__tmp644 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp643, i64 0, i64 1
  %__tmp645 = load i32, i32* %__tmp644, align 4
  %__tmp646 = mul i32 %__tmp645, -16
  %__tmp647 = add i32 %__tmp641, %__tmp646
  %__tmp648 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp649 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp648, i64 1
  %__tmp650 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp649, i64 0, i64 2
  %__tmp651 = load i32, i32* %__tmp650, align 4
  %__tmp652 = mul i32 %__tmp651, -70
  %__tmp653 = add i32 %__tmp647, %__tmp652
  %__tmp654 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp655 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp654, i64 1
  %__tmp656 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp655, i64 0, i64 3
  %__tmp657 = load i32, i32* %__tmp656, align 4
  %__tmp658 = mul i32 %__tmp657, 125
  %__tmp659 = add i32 %__tmp653, %__tmp658
  %__tmp660 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp661 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp660, i64 1
  %__tmp662 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp661, i64 0, i64 4
  %__tmp663 = load i32, i32* %__tmp662, align 4
  %__tmp664 = mul i32 %__tmp663, 75
  %__tmp665 = add i32 %__tmp659, %__tmp664
  %__tmp666 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp667 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp666, i64 2
  %__tmp668 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp667, i64 0, i64 0
  %__tmp669 = load i32, i32* %__tmp668, align 4
  %__tmp670 = mul i32 %__tmp669, 66
  %__tmp671 = add i32 %__tmp665, %__tmp670
  %__tmp672 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp673 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp672, i64 2
  %__tmp674 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp673, i64 0, i64 1
  %__tmp675 = load i32, i32* %__tmp674, align 4
  %__tmp676 = mul i32 %__tmp675, -96
  %__tmp677 = add i32 %__tmp671, %__tmp676
  %__tmp678 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp679 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp678, i64 2
  %__tmp680 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp679, i64 0, i64 2
  %__tmp681 = load i32, i32* %__tmp680, align 4
  %__tmp682 = mul i32 %__tmp681, -101
  %__tmp683 = add i32 %__tmp677, %__tmp682
  %__tmp684 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp685 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp684, i64 2
  %__tmp686 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp685, i64 0, i64 3
  %__tmp687 = load i32, i32* %__tmp686, align 4
  %__tmp688 = mul i32 %__tmp687, -114
  %__tmp689 = add i32 %__tmp683, %__tmp688
  %__tmp690 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp691 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp690, i64 2
  %__tmp692 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp691, i64 0, i64 4
  %__tmp693 = load i32, i32* %__tmp692, align 4
  %__tmp694 = mul i32 %__tmp693, 59
  %__tmp695 = add i32 %__tmp689, %__tmp694
  %__tmp696 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp697 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp696, i64 3
  %__tmp698 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp697, i64 0, i64 0
  %__tmp699 = load i32, i32* %__tmp698, align 4
  %__tmp700 = mul i32 %__tmp699, 12
  %__tmp701 = add i32 %__tmp695, %__tmp700
  %__tmp702 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp703 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp702, i64 3
  %__tmp704 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp703, i64 0, i64 1
  %__tmp705 = load i32, i32* %__tmp704, align 4
  %__tmp706 = mul i32 %__tmp705, 5
  %__tmp707 = add i32 %__tmp701, %__tmp706
  %__tmp708 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp709 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp708, i64 3
  %__tmp710 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp709, i64 0, i64 2
  %__tmp711 = load i32, i32* %__tmp710, align 4
  %__tmp712 = mul i32 %__tmp711, -95
  %__tmp713 = add i32 %__tmp707, %__tmp712
  %__tmp714 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp715 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp714, i64 3
  %__tmp716 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp715, i64 0, i64 3
  %__tmp717 = load i32, i32* %__tmp716, align 4
  %__tmp718 = mul i32 %__tmp717, 116
  %__tmp719 = add i32 %__tmp713, %__tmp718
  %__tmp720 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp721 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp720, i64 3
  %__tmp722 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp721, i64 0, i64 4
  %__tmp723 = load i32, i32* %__tmp722, align 4
  %__tmp724 = mul i32 %__tmp723, -93
  %__tmp725 = add i32 %__tmp719, %__tmp724
  %__tmp726 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp727 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp726, i64 4
  %__tmp728 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp727, i64 0, i64 0
  %__tmp729 = load i32, i32* %__tmp728, align 4
  %__tmp730 = mul i32 %__tmp729, 15
  %__tmp731 = add i32 %__tmp725, %__tmp730
  %__tmp732 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp733 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp732, i64 4
  %__tmp734 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp733, i64 0, i64 1
  %__tmp735 = load i32, i32* %__tmp734, align 4
  %__tmp736 = mul i32 %__tmp735, 79
  %__tmp737 = add i32 %__tmp731, %__tmp736
  %__tmp738 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp739 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp738, i64 4
  %__tmp740 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp739, i64 0, i64 2
  %__tmp741 = load i32, i32* %__tmp740, align 4
  %__tmp742 = mul i32 %__tmp741, 3
  %__tmp743 = add i32 %__tmp737, %__tmp742
  %__tmp744 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp745 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp744, i64 4
  %__tmp746 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp745, i64 0, i64 3
  %__tmp747 = load i32, i32* %__tmp746, align 4
  %__tmp748 = mul i32 %__tmp747, 49
  %__tmp749 = add i32 %__tmp743, %__tmp748
  %__tmp750 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp751 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp750, i64 4
  %__tmp752 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp751, i64 0, i64 4
  %__tmp753 = load i32, i32* %__tmp752, align 4
  %__tmp754 = mul i32 %__tmp753, -124
  %__tmp755 = add i32 %__tmp749, %__tmp754
  %__tmp756 = call i32 @relu_reg(i32 %__tmp755)
  %__tmp757 = mul i32 %__tmp756, -3
  %__tmp758 = add i32 %__tmp606, %__tmp757
  %__tmp759 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp760 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp759, i64 0
  %__tmp761 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp760, i64 0, i64 0
  %__tmp762 = load i32, i32* %__tmp761, align 4
  %__tmp763 = mul i32 %__tmp762, 81
  %__tmp764 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp765 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp764, i64 0
  %__tmp766 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp765, i64 0, i64 1
  %__tmp767 = load i32, i32* %__tmp766, align 4
  %__tmp768 = mul i32 %__tmp767, 68
  %__tmp769 = add i32 %__tmp763, %__tmp768
  %__tmp770 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp771 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp770, i64 0
  %__tmp772 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp771, i64 0, i64 2
  %__tmp773 = load i32, i32* %__tmp772, align 4
  %__tmp774 = mul i32 %__tmp773, -102
  %__tmp775 = add i32 %__tmp769, %__tmp774
  %__tmp776 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp777 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp776, i64 0
  %__tmp778 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp777, i64 0, i64 3
  %__tmp779 = load i32, i32* %__tmp778, align 4
  %__tmp780 = mul i32 %__tmp779, -74
  %__tmp781 = add i32 %__tmp775, %__tmp780
  %__tmp782 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp783 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp782, i64 0
  %__tmp784 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp783, i64 0, i64 4
  %__tmp785 = load i32, i32* %__tmp784, align 4
  %__tmp786 = mul i32 %__tmp785, 121
  %__tmp787 = add i32 %__tmp781, %__tmp786
  %__tmp788 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp789 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp788, i64 1
  %__tmp790 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp789, i64 0, i64 0
  %__tmp791 = load i32, i32* %__tmp790, align 4
  %__tmp792 = mul i32 %__tmp791, -15
  %__tmp793 = add i32 %__tmp787, %__tmp792
  %__tmp794 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp795 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp794, i64 1
  %__tmp796 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp795, i64 0, i64 1
  %__tmp797 = load i32, i32* %__tmp796, align 4
  %__tmp798 = mul i32 %__tmp797, 55
  %__tmp799 = add i32 %__tmp793, %__tmp798
  %__tmp800 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp801 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp800, i64 1
  %__tmp802 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp801, i64 0, i64 2
  %__tmp803 = load i32, i32* %__tmp802, align 4
  %__tmp804 = mul i32 %__tmp803, 101
  %__tmp805 = add i32 %__tmp799, %__tmp804
  %__tmp806 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp807 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp806, i64 1
  %__tmp808 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp807, i64 0, i64 3
  %__tmp809 = load i32, i32* %__tmp808, align 4
  %__tmp810 = mul i32 %__tmp809, -13
  %__tmp811 = add i32 %__tmp805, %__tmp810
  %__tmp812 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp813 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp812, i64 1
  %__tmp814 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp813, i64 0, i64 4
  %__tmp815 = load i32, i32* %__tmp814, align 4
  %__tmp816 = mul i32 %__tmp815, -62
  %__tmp817 = add i32 %__tmp811, %__tmp816
  %__tmp818 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp819 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp818, i64 2
  %__tmp820 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp819, i64 0, i64 0
  %__tmp821 = load i32, i32* %__tmp820, align 4
  %__tmp822 = mul i32 %__tmp821, 64
  %__tmp823 = add i32 %__tmp817, %__tmp822
  %__tmp824 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp825 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp824, i64 2
  %__tmp826 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp825, i64 0, i64 1
  %__tmp827 = load i32, i32* %__tmp826, align 4
  %__tmp828 = mul i32 %__tmp827, 114
  %__tmp829 = add i32 %__tmp823, %__tmp828
  %__tmp830 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp831 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp830, i64 2
  %__tmp832 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp831, i64 0, i64 2
  %__tmp833 = load i32, i32* %__tmp832, align 4
  %__tmp834 = mul i32 %__tmp833, 38
  %__tmp835 = add i32 %__tmp829, %__tmp834
  %__tmp836 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp837 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp836, i64 2
  %__tmp838 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp837, i64 0, i64 3
  %__tmp839 = load i32, i32* %__tmp838, align 4
  %__tmp840 = mul i32 %__tmp839, -21
  %__tmp841 = add i32 %__tmp835, %__tmp840
  %__tmp842 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp843 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp842, i64 2
  %__tmp844 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp843, i64 0, i64 4
  %__tmp845 = load i32, i32* %__tmp844, align 4
  %__tmp846 = mul i32 %__tmp845, 112
  %__tmp847 = add i32 %__tmp841, %__tmp846
  %__tmp848 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp849 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp848, i64 3
  %__tmp850 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp849, i64 0, i64 0
  %__tmp851 = load i32, i32* %__tmp850, align 4
  %__tmp852 = mul i32 %__tmp851, 114
  %__tmp853 = add i32 %__tmp847, %__tmp852
  %__tmp854 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp855 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp854, i64 3
  %__tmp856 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp855, i64 0, i64 1
  %__tmp857 = load i32, i32* %__tmp856, align 4
  %__tmp858 = mul i32 %__tmp857, 112
  %__tmp859 = add i32 %__tmp853, %__tmp858
  %__tmp860 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp861 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp860, i64 3
  %__tmp862 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp861, i64 0, i64 2
  %__tmp863 = load i32, i32* %__tmp862, align 4
  %__tmp864 = mul i32 %__tmp863, -10
  %__tmp865 = add i32 %__tmp859, %__tmp864
  %__tmp866 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp867 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp866, i64 3
  %__tmp868 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp867, i64 0, i64 3
  %__tmp869 = load i32, i32* %__tmp868, align 4
  %__tmp870 = mul i32 %__tmp869, -16
  %__tmp871 = add i32 %__tmp865, %__tmp870
  %__tmp872 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp873 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp872, i64 3
  %__tmp874 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp873, i64 0, i64 4
  %__tmp875 = load i32, i32* %__tmp874, align 4
  %__tmp876 = mul i32 %__tmp875, -50
  %__tmp877 = add i32 %__tmp871, %__tmp876
  %__tmp878 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp879 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp878, i64 4
  %__tmp880 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp879, i64 0, i64 0
  %__tmp881 = load i32, i32* %__tmp880, align 4
  %__tmp882 = mul i32 %__tmp881, -112
  %__tmp883 = add i32 %__tmp877, %__tmp882
  %__tmp884 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp885 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp884, i64 4
  %__tmp886 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp885, i64 0, i64 1
  %__tmp887 = load i32, i32* %__tmp886, align 4
  %__tmp888 = mul i32 %__tmp887, -116
  %__tmp889 = add i32 %__tmp883, %__tmp888
  %__tmp890 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp891 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp890, i64 4
  %__tmp892 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp891, i64 0, i64 2
  %__tmp893 = load i32, i32* %__tmp892, align 4
  %__tmp894 = mul i32 %__tmp893, -54
  %__tmp895 = add i32 %__tmp889, %__tmp894
  %__tmp896 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp897 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp896, i64 4
  %__tmp898 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp897, i64 0, i64 3
  %__tmp899 = load i32, i32* %__tmp898, align 4
  %__tmp900 = mul i32 %__tmp899, 82
  %__tmp901 = add i32 %__tmp895, %__tmp900
  %__tmp902 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp903 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp902, i64 4
  %__tmp904 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp903, i64 0, i64 4
  %__tmp905 = load i32, i32* %__tmp904, align 4
  %__tmp906 = mul i32 %__tmp905, -72
  %__tmp907 = add i32 %__tmp901, %__tmp906
  %__tmp908 = call i32 @relu_reg(i32 %__tmp907)
  %__tmp909 = mul i32 %__tmp908, 32
  %__tmp910 = add i32 %__tmp758, %__tmp909
  %__tmp911 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp912 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp911, i64 0
  %__tmp913 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp912, i64 0, i64 0
  %__tmp914 = load i32, i32* %__tmp913, align 4
  %__tmp915 = mul i32 %__tmp914, 15
  %__tmp916 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp917 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp916, i64 0
  %__tmp918 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp917, i64 0, i64 1
  %__tmp919 = load i32, i32* %__tmp918, align 4
  %__tmp920 = mul i32 %__tmp919, -77
  %__tmp921 = add i32 %__tmp915, %__tmp920
  %__tmp922 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp923 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp922, i64 0
  %__tmp924 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp923, i64 0, i64 2
  %__tmp925 = load i32, i32* %__tmp924, align 4
  %__tmp926 = mul i32 %__tmp925, 66
  %__tmp927 = add i32 %__tmp921, %__tmp926
  %__tmp928 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp929 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp928, i64 0
  %__tmp930 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp929, i64 0, i64 3
  %__tmp931 = load i32, i32* %__tmp930, align 4
  %__tmp932 = mul i32 %__tmp931, -90
  %__tmp933 = add i32 %__tmp927, %__tmp932
  %__tmp934 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp935 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp934, i64 0
  %__tmp936 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp935, i64 0, i64 4
  %__tmp937 = load i32, i32* %__tmp936, align 4
  %__tmp938 = mul i32 %__tmp937, -6
  %__tmp939 = add i32 %__tmp933, %__tmp938
  %__tmp940 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp941 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp940, i64 1
  %__tmp942 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp941, i64 0, i64 0
  %__tmp943 = load i32, i32* %__tmp942, align 4
  %__tmp944 = mul i32 %__tmp943, -30
  %__tmp945 = add i32 %__tmp939, %__tmp944
  %__tmp946 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp947 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp946, i64 1
  %__tmp948 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp947, i64 0, i64 1
  %__tmp949 = load i32, i32* %__tmp948, align 4
  %__tmp950 = mul i32 %__tmp949, -8
  %__tmp951 = add i32 %__tmp945, %__tmp950
  %__tmp952 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp953 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp952, i64 1
  %__tmp954 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp953, i64 0, i64 2
  %__tmp955 = load i32, i32* %__tmp954, align 4
  %__tmp956 = mul i32 %__tmp955, 81
  %__tmp957 = add i32 %__tmp951, %__tmp956
  %__tmp958 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp959 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp958, i64 1
  %__tmp960 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp959, i64 0, i64 3
  %__tmp961 = load i32, i32* %__tmp960, align 4
  %__tmp962 = mul i32 %__tmp961, 2
  %__tmp963 = add i32 %__tmp957, %__tmp962
  %__tmp964 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp965 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp964, i64 1
  %__tmp966 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp965, i64 0, i64 4
  %__tmp967 = load i32, i32* %__tmp966, align 4
  %__tmp968 = mul i32 %__tmp967, -110
  %__tmp969 = add i32 %__tmp963, %__tmp968
  %__tmp970 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp971 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp970, i64 2
  %__tmp972 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp971, i64 0, i64 0
  %__tmp973 = load i32, i32* %__tmp972, align 4
  %__tmp974 = mul i32 %__tmp973, -95
  %__tmp975 = add i32 %__tmp969, %__tmp974
  %__tmp976 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp977 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp976, i64 2
  %__tmp978 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp977, i64 0, i64 1
  %__tmp979 = load i32, i32* %__tmp978, align 4
  %__tmp980 = mul i32 %__tmp979, 59
  %__tmp981 = add i32 %__tmp975, %__tmp980
  %__tmp982 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp983 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp982, i64 2
  %__tmp984 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp983, i64 0, i64 2
  %__tmp985 = load i32, i32* %__tmp984, align 4
  %__tmp986 = mul i32 %__tmp985, 52
  %__tmp987 = add i32 %__tmp981, %__tmp986
  %__tmp988 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp989 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp988, i64 2
  %__tmp990 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp989, i64 0, i64 3
  %__tmp991 = load i32, i32* %__tmp990, align 4
  %__tmp992 = mul i32 %__tmp991, 15
  %__tmp993 = add i32 %__tmp987, %__tmp992
  %__tmp994 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp995 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp994, i64 2
  %__tmp996 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp995, i64 0, i64 4
  %__tmp997 = load i32, i32* %__tmp996, align 4
  %__tmp998 = mul i32 %__tmp997, 55
  %__tmp999 = add i32 %__tmp993, %__tmp998
  %__tmp1000 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1001 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1000, i64 3
  %__tmp1002 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1001, i64 0, i64 0
  %__tmp1003 = load i32, i32* %__tmp1002, align 4
  %__tmp1004 = mul i32 %__tmp1003, -33
  %__tmp1005 = add i32 %__tmp999, %__tmp1004
  %__tmp1006 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1007 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1006, i64 3
  %__tmp1008 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1007, i64 0, i64 1
  %__tmp1009 = load i32, i32* %__tmp1008, align 4
  %__tmp1010 = mul i32 %__tmp1009, 14
  %__tmp1011 = add i32 %__tmp1005, %__tmp1010
  %__tmp1012 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1013 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1012, i64 3
  %__tmp1014 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1013, i64 0, i64 2
  %__tmp1015 = load i32, i32* %__tmp1014, align 4
  %__tmp1016 = mul i32 %__tmp1015, 58
  %__tmp1017 = add i32 %__tmp1011, %__tmp1016
  %__tmp1018 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1019 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1018, i64 3
  %__tmp1020 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1019, i64 0, i64 3
  %__tmp1021 = load i32, i32* %__tmp1020, align 4
  %__tmp1022 = mul i32 %__tmp1021, 67
  %__tmp1023 = add i32 %__tmp1017, %__tmp1022
  %__tmp1024 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1025 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1024, i64 3
  %__tmp1026 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1025, i64 0, i64 4
  %__tmp1027 = load i32, i32* %__tmp1026, align 4
  %__tmp1028 = mul i32 %__tmp1027, 86
  %__tmp1029 = add i32 %__tmp1023, %__tmp1028
  %__tmp1030 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1031 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1030, i64 4
  %__tmp1032 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1031, i64 0, i64 0
  %__tmp1033 = load i32, i32* %__tmp1032, align 4
  %__tmp1034 = mul i32 %__tmp1033, -79
  %__tmp1035 = add i32 %__tmp1029, %__tmp1034
  %__tmp1036 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1037 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1036, i64 4
  %__tmp1038 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1037, i64 0, i64 1
  %__tmp1039 = load i32, i32* %__tmp1038, align 4
  %__tmp1040 = mul i32 %__tmp1039, 48
  %__tmp1041 = add i32 %__tmp1035, %__tmp1040
  %__tmp1042 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1043 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1042, i64 4
  %__tmp1044 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1043, i64 0, i64 2
  %__tmp1045 = load i32, i32* %__tmp1044, align 4
  %__tmp1046 = mul i32 %__tmp1045, -13
  %__tmp1047 = add i32 %__tmp1041, %__tmp1046
  %__tmp1048 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1049 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1048, i64 4
  %__tmp1050 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1049, i64 0, i64 3
  %__tmp1051 = load i32, i32* %__tmp1050, align 4
  %__tmp1052 = mul i32 %__tmp1051, -15
  %__tmp1053 = add i32 %__tmp1047, %__tmp1052
  %__tmp1054 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1055 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1054, i64 4
  %__tmp1056 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1055, i64 0, i64 4
  %__tmp1057 = load i32, i32* %__tmp1056, align 4
  %__tmp1058 = mul i32 %__tmp1057, 66
  %__tmp1059 = add i32 %__tmp1053, %__tmp1058
  %__tmp1060 = call i32 @relu_reg(i32 %__tmp1059)
  %__tmp1061 = mul i32 %__tmp1060, -95
  %__tmp1062 = add i32 %__tmp910, %__tmp1061
  %__tmp1063 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1064 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1063, i64 0
  %__tmp1065 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1064, i64 0, i64 0
  %__tmp1066 = load i32, i32* %__tmp1065, align 4
  %__tmp1067 = mul i32 %__tmp1066, 33
  %__tmp1068 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1069 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1068, i64 0
  %__tmp1070 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1069, i64 0, i64 1
  %__tmp1071 = load i32, i32* %__tmp1070, align 4
  %__tmp1072 = mul i32 %__tmp1071, 82
  %__tmp1073 = add i32 %__tmp1067, %__tmp1072
  %__tmp1074 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1075 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1074, i64 0
  %__tmp1076 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1075, i64 0, i64 2
  %__tmp1077 = load i32, i32* %__tmp1076, align 4
  %__tmp1078 = mul i32 %__tmp1077, 67
  %__tmp1079 = add i32 %__tmp1073, %__tmp1078
  %__tmp1080 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1081 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1080, i64 0
  %__tmp1082 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1081, i64 0, i64 3
  %__tmp1083 = load i32, i32* %__tmp1082, align 4
  %__tmp1084 = mul i32 %__tmp1083, 30
  %__tmp1085 = add i32 %__tmp1079, %__tmp1084
  %__tmp1086 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1087 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1086, i64 0
  %__tmp1088 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1087, i64 0, i64 4
  %__tmp1089 = load i32, i32* %__tmp1088, align 4
  %__tmp1090 = mul i32 %__tmp1089, -2
  %__tmp1091 = add i32 %__tmp1085, %__tmp1090
  %__tmp1092 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1093 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1092, i64 1
  %__tmp1094 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1093, i64 0, i64 0
  %__tmp1095 = load i32, i32* %__tmp1094, align 4
  %__tmp1096 = mul i32 %__tmp1095, 65
  %__tmp1097 = add i32 %__tmp1091, %__tmp1096
  %__tmp1098 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1099 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1098, i64 1
  %__tmp1100 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1099, i64 0, i64 1
  %__tmp1101 = load i32, i32* %__tmp1100, align 4
  %__tmp1102 = mul i32 %__tmp1101, 120
  %__tmp1103 = add i32 %__tmp1097, %__tmp1102
  %__tmp1104 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1105 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1104, i64 1
  %__tmp1106 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1105, i64 0, i64 2
  %__tmp1107 = load i32, i32* %__tmp1106, align 4
  %__tmp1108 = mul i32 %__tmp1107, -13
  %__tmp1109 = add i32 %__tmp1103, %__tmp1108
  %__tmp1110 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1111 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1110, i64 1
  %__tmp1112 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1111, i64 0, i64 3
  %__tmp1113 = load i32, i32* %__tmp1112, align 4
  %__tmp1114 = mul i32 %__tmp1113, 18
  %__tmp1115 = add i32 %__tmp1109, %__tmp1114
  %__tmp1116 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1117 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1116, i64 1
  %__tmp1118 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1117, i64 0, i64 4
  %__tmp1119 = load i32, i32* %__tmp1118, align 4
  %__tmp1120 = mul i32 %__tmp1119, 5
  %__tmp1121 = add i32 %__tmp1115, %__tmp1120
  %__tmp1122 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1123 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1122, i64 2
  %__tmp1124 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1123, i64 0, i64 0
  %__tmp1125 = load i32, i32* %__tmp1124, align 4
  %__tmp1126 = mul i32 %__tmp1125, 104
  %__tmp1127 = add i32 %__tmp1121, %__tmp1126
  %__tmp1128 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1129 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1128, i64 2
  %__tmp1130 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1129, i64 0, i64 1
  %__tmp1131 = load i32, i32* %__tmp1130, align 4
  %__tmp1132 = mul i32 %__tmp1131, -119
  %__tmp1133 = add i32 %__tmp1127, %__tmp1132
  %__tmp1134 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1135 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1134, i64 2
  %__tmp1136 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1135, i64 0, i64 2
  %__tmp1137 = load i32, i32* %__tmp1136, align 4
  %__tmp1138 = mul i32 %__tmp1137, -7
  %__tmp1139 = add i32 %__tmp1133, %__tmp1138
  %__tmp1140 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1141 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1140, i64 2
  %__tmp1142 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1141, i64 0, i64 3
  %__tmp1143 = load i32, i32* %__tmp1142, align 4
  %__tmp1144 = mul i32 %__tmp1143, 71
  %__tmp1145 = add i32 %__tmp1139, %__tmp1144
  %__tmp1146 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1147 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1146, i64 2
  %__tmp1148 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1147, i64 0, i64 4
  %__tmp1149 = load i32, i32* %__tmp1148, align 4
  %__tmp1150 = mul i32 %__tmp1149, 107
  %__tmp1151 = add i32 %__tmp1145, %__tmp1150
  %__tmp1152 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1153 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1152, i64 3
  %__tmp1154 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1153, i64 0, i64 0
  %__tmp1155 = load i32, i32* %__tmp1154, align 4
  %__tmp1156 = mul i32 %__tmp1155, 24
  %__tmp1157 = add i32 %__tmp1151, %__tmp1156
  %__tmp1158 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1159 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1158, i64 3
  %__tmp1160 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1159, i64 0, i64 1
  %__tmp1161 = load i32, i32* %__tmp1160, align 4
  %__tmp1162 = mul i32 %__tmp1161, 82
  %__tmp1163 = add i32 %__tmp1157, %__tmp1162
  %__tmp1164 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1165 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1164, i64 3
  %__tmp1166 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1165, i64 0, i64 2
  %__tmp1167 = load i32, i32* %__tmp1166, align 4
  %__tmp1168 = mul i32 %__tmp1167, -96
  %__tmp1169 = add i32 %__tmp1163, %__tmp1168
  %__tmp1170 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1171 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1170, i64 3
  %__tmp1172 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1171, i64 0, i64 3
  %__tmp1173 = load i32, i32* %__tmp1172, align 4
  %__tmp1174 = mul i32 %__tmp1173, -104
  %__tmp1175 = add i32 %__tmp1169, %__tmp1174
  %__tmp1176 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1177 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1176, i64 3
  %__tmp1178 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1177, i64 0, i64 4
  %__tmp1179 = load i32, i32* %__tmp1178, align 4
  %__tmp1180 = mul i32 %__tmp1179, -121
  %__tmp1181 = add i32 %__tmp1175, %__tmp1180
  %__tmp1182 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1183 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1182, i64 4
  %__tmp1184 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1183, i64 0, i64 0
  %__tmp1185 = load i32, i32* %__tmp1184, align 4
  %__tmp1186 = mul i32 %__tmp1185, 65
  %__tmp1187 = add i32 %__tmp1181, %__tmp1186
  %__tmp1188 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1189 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1188, i64 4
  %__tmp1190 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1189, i64 0, i64 1
  %__tmp1191 = load i32, i32* %__tmp1190, align 4
  %__tmp1192 = mul i32 %__tmp1191, 97
  %__tmp1193 = add i32 %__tmp1187, %__tmp1192
  %__tmp1194 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1195 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1194, i64 4
  %__tmp1196 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1195, i64 0, i64 2
  %__tmp1197 = load i32, i32* %__tmp1196, align 4
  %__tmp1198 = mul i32 %__tmp1197, 83
  %__tmp1199 = add i32 %__tmp1193, %__tmp1198
  %__tmp1200 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1201 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1200, i64 4
  %__tmp1202 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1201, i64 0, i64 3
  %__tmp1203 = load i32, i32* %__tmp1202, align 4
  %__tmp1204 = mul i32 %__tmp1203, 46
  %__tmp1205 = add i32 %__tmp1199, %__tmp1204
  %__tmp1206 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1207 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1206, i64 4
  %__tmp1208 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1207, i64 0, i64 4
  %__tmp1209 = load i32, i32* %__tmp1208, align 4
  %__tmp1210 = mul i32 %__tmp1209, -84
  %__tmp1211 = add i32 %__tmp1205, %__tmp1210
  %__tmp1212 = call i32 @relu_reg(i32 %__tmp1211)
  %__tmp1213 = mul i32 %__tmp1212, -50
  %__tmp1214 = add i32 %__tmp1062, %__tmp1213
  %__tmp1215 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1216 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1215, i64 0
  %__tmp1217 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1216, i64 0, i64 0
  %__tmp1218 = load i32, i32* %__tmp1217, align 4
  %__tmp1219 = mul i32 %__tmp1218, -29
  %__tmp1220 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1221 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1220, i64 0
  %__tmp1222 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1221, i64 0, i64 1
  %__tmp1223 = load i32, i32* %__tmp1222, align 4
  %__tmp1224 = mul i32 %__tmp1223, 7
  %__tmp1225 = add i32 %__tmp1219, %__tmp1224
  %__tmp1226 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1227 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1226, i64 0
  %__tmp1228 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1227, i64 0, i64 2
  %__tmp1229 = load i32, i32* %__tmp1228, align 4
  %__tmp1230 = mul i32 %__tmp1229, -70
  %__tmp1231 = add i32 %__tmp1225, %__tmp1230
  %__tmp1232 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1233 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1232, i64 0
  %__tmp1234 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1233, i64 0, i64 3
  %__tmp1235 = load i32, i32* %__tmp1234, align 4
  %__tmp1236 = mul i32 %__tmp1235, 38
  %__tmp1237 = add i32 %__tmp1231, %__tmp1236
  %__tmp1238 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1239 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1238, i64 0
  %__tmp1240 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1239, i64 0, i64 4
  %__tmp1241 = load i32, i32* %__tmp1240, align 4
  %__tmp1242 = mul i32 %__tmp1241, -90
  %__tmp1243 = add i32 %__tmp1237, %__tmp1242
  %__tmp1244 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1245 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1244, i64 1
  %__tmp1246 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1245, i64 0, i64 0
  %__tmp1247 = load i32, i32* %__tmp1246, align 4
  %__tmp1248 = mul i32 %__tmp1247, -15
  %__tmp1249 = add i32 %__tmp1243, %__tmp1248
  %__tmp1250 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1251 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1250, i64 1
  %__tmp1252 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1251, i64 0, i64 1
  %__tmp1253 = load i32, i32* %__tmp1252, align 4
  %__tmp1254 = mul i32 %__tmp1253, -32
  %__tmp1255 = add i32 %__tmp1249, %__tmp1254
  %__tmp1256 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1257 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1256, i64 1
  %__tmp1258 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1257, i64 0, i64 2
  %__tmp1259 = load i32, i32* %__tmp1258, align 4
  %__tmp1260 = mul i32 %__tmp1259, 37
  %__tmp1261 = add i32 %__tmp1255, %__tmp1260
  %__tmp1262 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1263 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1262, i64 1
  %__tmp1264 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1263, i64 0, i64 3
  %__tmp1265 = load i32, i32* %__tmp1264, align 4
  %__tmp1266 = mul i32 %__tmp1265, 36
  %__tmp1267 = add i32 %__tmp1261, %__tmp1266
  %__tmp1268 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1269 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1268, i64 1
  %__tmp1270 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1269, i64 0, i64 4
  %__tmp1271 = load i32, i32* %__tmp1270, align 4
  %__tmp1272 = mul i32 %__tmp1271, -62
  %__tmp1273 = add i32 %__tmp1267, %__tmp1272
  %__tmp1274 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1275 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1274, i64 2
  %__tmp1276 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1275, i64 0, i64 0
  %__tmp1277 = load i32, i32* %__tmp1276, align 4
  %__tmp1278 = mul i32 %__tmp1277, -125
  %__tmp1279 = add i32 %__tmp1273, %__tmp1278
  %__tmp1280 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1281 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1280, i64 2
  %__tmp1282 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1281, i64 0, i64 1
  %__tmp1283 = load i32, i32* %__tmp1282, align 4
  %__tmp1284 = mul i32 %__tmp1283, -46
  %__tmp1285 = add i32 %__tmp1279, %__tmp1284
  %__tmp1286 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1287 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1286, i64 2
  %__tmp1288 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1287, i64 0, i64 2
  %__tmp1289 = load i32, i32* %__tmp1288, align 4
  %__tmp1290 = mul i32 %__tmp1289, -70
  %__tmp1291 = add i32 %__tmp1285, %__tmp1290
  %__tmp1292 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1293 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1292, i64 2
  %__tmp1294 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1293, i64 0, i64 3
  %__tmp1295 = load i32, i32* %__tmp1294, align 4
  %__tmp1296 = mul i32 %__tmp1295, 37
  %__tmp1297 = add i32 %__tmp1291, %__tmp1296
  %__tmp1298 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1299 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1298, i64 2
  %__tmp1300 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1299, i64 0, i64 4
  %__tmp1301 = load i32, i32* %__tmp1300, align 4
  %__tmp1302 = mul i32 %__tmp1301, -73
  %__tmp1303 = add i32 %__tmp1297, %__tmp1302
  %__tmp1304 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1305 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1304, i64 3
  %__tmp1306 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1305, i64 0, i64 0
  %__tmp1307 = load i32, i32* %__tmp1306, align 4
  %__tmp1308 = mul i32 %__tmp1307, -34
  %__tmp1309 = add i32 %__tmp1303, %__tmp1308
  %__tmp1310 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1311 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1310, i64 3
  %__tmp1312 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1311, i64 0, i64 1
  %__tmp1313 = load i32, i32* %__tmp1312, align 4
  %__tmp1314 = mul i32 %__tmp1313, -87
  %__tmp1315 = add i32 %__tmp1309, %__tmp1314
  %__tmp1316 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1317 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1316, i64 3
  %__tmp1318 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1317, i64 0, i64 2
  %__tmp1319 = load i32, i32* %__tmp1318, align 4
  %__tmp1320 = mul i32 %__tmp1319, -75
  %__tmp1321 = add i32 %__tmp1315, %__tmp1320
  %__tmp1322 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1323 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1322, i64 3
  %__tmp1324 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1323, i64 0, i64 3
  %__tmp1325 = load i32, i32* %__tmp1324, align 4
  %__tmp1326 = mul i32 %__tmp1325, 71
  %__tmp1327 = add i32 %__tmp1321, %__tmp1326
  %__tmp1328 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1329 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1328, i64 3
  %__tmp1330 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1329, i64 0, i64 4
  %__tmp1331 = load i32, i32* %__tmp1330, align 4
  %__tmp1332 = mul i32 %__tmp1331, -77
  %__tmp1333 = add i32 %__tmp1327, %__tmp1332
  %__tmp1334 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1335 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1334, i64 4
  %__tmp1336 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1335, i64 0, i64 0
  %__tmp1337 = load i32, i32* %__tmp1336, align 4
  %__tmp1338 = mul i32 %__tmp1337, 53
  %__tmp1339 = add i32 %__tmp1333, %__tmp1338
  %__tmp1340 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1341 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1340, i64 4
  %__tmp1342 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1341, i64 0, i64 1
  %__tmp1343 = load i32, i32* %__tmp1342, align 4
  %__tmp1344 = mul i32 %__tmp1343, 37
  %__tmp1345 = add i32 %__tmp1339, %__tmp1344
  %__tmp1346 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1347 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1346, i64 4
  %__tmp1348 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1347, i64 0, i64 2
  %__tmp1349 = load i32, i32* %__tmp1348, align 4
  %__tmp1350 = mul i32 %__tmp1349, -103
  %__tmp1351 = add i32 %__tmp1345, %__tmp1350
  %__tmp1352 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1353 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1352, i64 4
  %__tmp1354 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1353, i64 0, i64 3
  %__tmp1355 = load i32, i32* %__tmp1354, align 4
  %__tmp1356 = mul i32 %__tmp1355, -13
  %__tmp1357 = add i32 %__tmp1351, %__tmp1356
  %__tmp1358 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1359 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1358, i64 4
  %__tmp1360 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1359, i64 0, i64 4
  %__tmp1361 = load i32, i32* %__tmp1360, align 4
  %__tmp1362 = mul i32 %__tmp1361, -114
  %__tmp1363 = add i32 %__tmp1357, %__tmp1362
  %__tmp1364 = call i32 @relu_reg(i32 %__tmp1363)
  %__tmp1365 = mul i32 %__tmp1364, -23
  %__tmp1366 = add i32 %__tmp1214, %__tmp1365
  %__tmp1367 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1368 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1367, i64 0
  %__tmp1369 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1368, i64 0, i64 0
  %__tmp1370 = load i32, i32* %__tmp1369, align 4
  %__tmp1371 = mul i32 %__tmp1370, 67
  %__tmp1372 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1373 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1372, i64 0
  %__tmp1374 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1373, i64 0, i64 1
  %__tmp1375 = load i32, i32* %__tmp1374, align 4
  %__tmp1376 = mul i32 %__tmp1375, 42
  %__tmp1377 = add i32 %__tmp1371, %__tmp1376
  %__tmp1378 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1379 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1378, i64 0
  %__tmp1380 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1379, i64 0, i64 2
  %__tmp1381 = load i32, i32* %__tmp1380, align 4
  %__tmp1382 = mul i32 %__tmp1381, 41
  %__tmp1383 = add i32 %__tmp1377, %__tmp1382
  %__tmp1384 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1385 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1384, i64 0
  %__tmp1386 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1385, i64 0, i64 3
  %__tmp1387 = load i32, i32* %__tmp1386, align 4
  %__tmp1388 = mul i32 %__tmp1387, -123
  %__tmp1389 = add i32 %__tmp1383, %__tmp1388
  %__tmp1390 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1391 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1390, i64 0
  %__tmp1392 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1391, i64 0, i64 4
  %__tmp1393 = load i32, i32* %__tmp1392, align 4
  %__tmp1394 = mul i32 %__tmp1393, -92
  %__tmp1395 = add i32 %__tmp1389, %__tmp1394
  %__tmp1396 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1397 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1396, i64 1
  %__tmp1398 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1397, i64 0, i64 0
  %__tmp1399 = load i32, i32* %__tmp1398, align 4
  %__tmp1400 = mul i32 %__tmp1399, 10
  %__tmp1401 = add i32 %__tmp1395, %__tmp1400
  %__tmp1402 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1403 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1402, i64 1
  %__tmp1404 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1403, i64 0, i64 1
  %__tmp1405 = load i32, i32* %__tmp1404, align 4
  %__tmp1406 = mul i32 %__tmp1405, -77
  %__tmp1407 = add i32 %__tmp1401, %__tmp1406
  %__tmp1408 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1409 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1408, i64 1
  %__tmp1410 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1409, i64 0, i64 2
  %__tmp1411 = load i32, i32* %__tmp1410, align 4
  %__tmp1412 = mul i32 %__tmp1411, 75
  %__tmp1413 = add i32 %__tmp1407, %__tmp1412
  %__tmp1414 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1415 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1414, i64 1
  %__tmp1416 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1415, i64 0, i64 3
  %__tmp1417 = load i32, i32* %__tmp1416, align 4
  %__tmp1418 = mul i32 %__tmp1417, 96
  %__tmp1419 = add i32 %__tmp1413, %__tmp1418
  %__tmp1420 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1421 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1420, i64 1
  %__tmp1422 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1421, i64 0, i64 4
  %__tmp1423 = load i32, i32* %__tmp1422, align 4
  %__tmp1424 = mul i32 %__tmp1423, -51
  %__tmp1425 = add i32 %__tmp1419, %__tmp1424
  %__tmp1426 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1427 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1426, i64 2
  %__tmp1428 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1427, i64 0, i64 0
  %__tmp1429 = load i32, i32* %__tmp1428, align 4
  %__tmp1430 = mul i32 %__tmp1429, 109
  %__tmp1431 = add i32 %__tmp1425, %__tmp1430
  %__tmp1432 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1433 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1432, i64 2
  %__tmp1434 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1433, i64 0, i64 1
  %__tmp1435 = load i32, i32* %__tmp1434, align 4
  %__tmp1436 = mul i32 %__tmp1435, -74
  %__tmp1437 = add i32 %__tmp1431, %__tmp1436
  %__tmp1438 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1439 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1438, i64 2
  %__tmp1440 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1439, i64 0, i64 2
  %__tmp1441 = load i32, i32* %__tmp1440, align 4
  %__tmp1442 = mul i32 %__tmp1441, -7
  %__tmp1443 = add i32 %__tmp1437, %__tmp1442
  %__tmp1444 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1445 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1444, i64 2
  %__tmp1446 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1445, i64 0, i64 3
  %__tmp1447 = load i32, i32* %__tmp1446, align 4
  %__tmp1448 = mul i32 %__tmp1447, -122
  %__tmp1449 = add i32 %__tmp1443, %__tmp1448
  %__tmp1450 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1451 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1450, i64 2
  %__tmp1452 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1451, i64 0, i64 4
  %__tmp1453 = load i32, i32* %__tmp1452, align 4
  %__tmp1454 = mul i32 %__tmp1453, 67
  %__tmp1455 = add i32 %__tmp1449, %__tmp1454
  %__tmp1456 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1457 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1456, i64 3
  %__tmp1458 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1457, i64 0, i64 0
  %__tmp1459 = load i32, i32* %__tmp1458, align 4
  %__tmp1460 = mul i32 %__tmp1459, 47
  %__tmp1461 = add i32 %__tmp1455, %__tmp1460
  %__tmp1462 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1463 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1462, i64 3
  %__tmp1464 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1463, i64 0, i64 1
  %__tmp1465 = load i32, i32* %__tmp1464, align 4
  %__tmp1466 = mul i32 %__tmp1465, 22
  %__tmp1467 = add i32 %__tmp1461, %__tmp1466
  %__tmp1468 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1469 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1468, i64 3
  %__tmp1470 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1469, i64 0, i64 2
  %__tmp1471 = load i32, i32* %__tmp1470, align 4
  %__tmp1472 = mul i32 %__tmp1471, -68
  %__tmp1473 = add i32 %__tmp1467, %__tmp1472
  %__tmp1474 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1475 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1474, i64 3
  %__tmp1476 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1475, i64 0, i64 3
  %__tmp1477 = load i32, i32* %__tmp1476, align 4
  %__tmp1478 = mul i32 %__tmp1477, 38
  %__tmp1479 = add i32 %__tmp1473, %__tmp1478
  %__tmp1480 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1481 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1480, i64 3
  %__tmp1482 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1481, i64 0, i64 4
  %__tmp1483 = load i32, i32* %__tmp1482, align 4
  %__tmp1484 = mul i32 %__tmp1483, 29
  %__tmp1485 = add i32 %__tmp1479, %__tmp1484
  %__tmp1486 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1487 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1486, i64 4
  %__tmp1488 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1487, i64 0, i64 0
  %__tmp1489 = load i32, i32* %__tmp1488, align 4
  %__tmp1490 = mul i32 %__tmp1489, 115
  %__tmp1491 = add i32 %__tmp1485, %__tmp1490
  %__tmp1492 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1493 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1492, i64 4
  %__tmp1494 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1493, i64 0, i64 1
  %__tmp1495 = load i32, i32* %__tmp1494, align 4
  %__tmp1496 = mul i32 %__tmp1495, -121
  %__tmp1497 = add i32 %__tmp1491, %__tmp1496
  %__tmp1498 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1499 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1498, i64 4
  %__tmp1500 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1499, i64 0, i64 2
  %__tmp1501 = load i32, i32* %__tmp1500, align 4
  %__tmp1502 = mul i32 %__tmp1501, 36
  %__tmp1503 = add i32 %__tmp1497, %__tmp1502
  %__tmp1504 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1505 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1504, i64 4
  %__tmp1506 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1505, i64 0, i64 3
  %__tmp1507 = load i32, i32* %__tmp1506, align 4
  %__tmp1508 = mul i32 %__tmp1507, -49
  %__tmp1509 = add i32 %__tmp1503, %__tmp1508
  %__tmp1510 = load [5 x i32]*, [5 x i32]** %a_arg, align 4
  %__tmp1511 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1510, i64 4
  %__tmp1512 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp1511, i64 0, i64 4
  %__tmp1513 = load i32, i32* %__tmp1512, align 4
  %__tmp1514 = mul i32 %__tmp1513, 85
  %__tmp1515 = add i32 %__tmp1509, %__tmp1514
  %__tmp1516 = call i32 @relu_reg(i32 %__tmp1515)
  %__tmp1517 = mul i32 %__tmp1516, 46
  %__tmp1518 = add i32 %__tmp1366, %__tmp1517
  %__tmp1519 = icmp sgt i32 %__tmp1518, 0
  br i1 %__tmp1519, label %bb0, label %bb1
bb0:
  ret i32 1
bb1:
  br label %bb2
bb2:
  ret i32 0
}

define i32 @main() {
mainEntry:
  %N = alloca i32, align 4
  %__tmp0 = call i32 @getint()
  store i32 %__tmp0, i32* %N, align 4
  %a = alloca [5 x [5 x i32]], align 4
  store [5 x [5 x i32]] zeroinitializer, [5 x [5 x i32]]* %a, align 4
  br label %bb0
bb0:
  %__tmp1 = load i32, i32* %N, align 4
  %__tmp2 = icmp sgt i32 %__tmp1, 0
  br i1 %__tmp2, label %bb1, label %bb2
bb1:
  %i = alloca i32, align 4
  store i32 0, i32* %i, align 4
  br label %bb3
bb3:
  %__tmp3 = load i32, i32* %i, align 4
  %__tmp4 = icmp slt i32 %__tmp3, 5
  br i1 %__tmp4, label %bb4, label %bb5
bb4:
  %j = alloca i32, align 4
  store i32 0, i32* %j, align 4
  br label %bb6
bb6:
  %__tmp5 = load i32, i32* %j, align 4
  %__tmp6 = icmp slt i32 %__tmp5, 5
  br i1 %__tmp6, label %bb7, label %bb8
bb7:
  %__tmp7 = load i32, i32* %i, align 4
  %__tmp8 = sext i32 %__tmp7 to i64
  %__tmp9 = getelementptr inbounds [5 x [5 x i32]], [5 x [5 x i32]]* %a, i64 0, i64 %__tmp8
  %__tmp10 = load i32, i32* %j, align 4
  %__tmp11 = sext i32 %__tmp10 to i64
  %__tmp12 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp9, i64 0, i64 %__tmp11
  %__tmp13 = call i32 @getint()
  store i32 %__tmp13, i32* %__tmp12, align 4
  %__tmp14 = load i32, i32* %j, align 4
  %__tmp15 = add i32 %__tmp14, 1
  store i32 %__tmp15, i32* %j, align 4
  br label %bb6
bb8:
  %__tmp16 = load i32, i32* %i, align 4
  %__tmp17 = add i32 %__tmp16, 1
  store i32 %__tmp17, i32* %i, align 4
  br label %bb3
bb5:
  %__tmp18 = getelementptr inbounds [5 x [5 x i32]], [5 x [5 x i32]]* %a, i64 0, i64 0
  %__tmp19 = getelementptr inbounds [5 x i32], [5 x i32]* %__tmp18, i64 0, i64 0
  %__tmp20 = call i32 @model(i32* %__tmp19)
  %__tmp21 = icmp ne i32 %__tmp20, 0
  br i1 %__tmp21, label %bb9, label %bb10
bb9:
  call void @putch(i32 99)
  call void @putch(i32 97)
  call void @putch(i32 116)
  call void @putch(i32 10)
  br label %bb11
bb10:
  call void @putch(i32 100)
  call void @putch(i32 111)
  call void @putch(i32 103)
  call void @putch(i32 10)
  br label %bb11
bb11:
  %__tmp22 = load i32, i32* %N, align 4
  %__tmp23 = sub i32 %__tmp22, 1
  store i32 %__tmp23, i32* %N, align 4
  br label %bb0
bb2:
  ret i32 0
}

